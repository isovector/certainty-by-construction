# Functions, Big and Small

```agda
module functions where
```

Computer science is chocked full of data structures. A great many come from the
official pantheon---things like binary search trees, hash maps, stacks, graphs,
and heaps. But, dwarfing all of these, there exists orders of magnitude more
data structures in the arcane vault, from the
passingly-familiar-but-unlikely-to-have-implemented *rope* to the obscure *Judy
array.* With so many options to choose from, how can we even hope to make an
informed choice?

The reason there exist many more data structures than any practitioner can
possibly know about is that most data structures are minor tweaks of other
well-known structures. For example, the UB-tree is a variation on the B+ tree,
which itself is a B-tree that maintains a particular invariant, while a B-tree
is a generalization of the binary search tree (BST henceforth). Unrolling the
lineage here shows us that whatever the UB-tree is, it's probably a BST that has
more desirable computational properties for certain shapes of data.

As Donald Knuth said, "premature optimization is the root of all evil." For the
vast majority of tasks, you can start with (and subsequently get away with) a
BST, upgrading to the more complex UB-tree in the future only if it turns out to
be mission critical. This is a well-understood idea in the modern age.

However, most programmers coming to Agda make an error in the spirit of the
Co-Blub paradox. After years of honing their taste and cutting their teeth on
picking the simplest data structure for the job, they come to Agda and
immediately fall down the rabbit-hole of long, arduous proofs. As I have gotten
older and more experienced, my guiding philosophy for writing software has
become *if it feels too hard, it probably is.*

As it happens, your choice of representation matters much more in Agda than it
does in most programming languages. That arises from the fact that your proofs
will inevitably trace the same grooves as the implementations they are proofs
*about.* In other words, the proof follows the implementation. It's not hard to
imagine that a complicated implementation will warrant a complicated proof.


## Matrices

Let's work through an example together, to get a feel for just how important a
representation can be. Our object of investigation will be *matrices*---that is,
rectangular arrays of numbers. Matrices are often used in computational
geometry, including 3D graphics, and are the back-bone of modern machine
learning techniques. As an exercise in honing our
translating-mathematics-to-Agda chops, let's take a look at the definition of a
matrix.

Matrix
:   A rectangular array of numbers.

Matrices have a predefined height and width, often referred to as $m$ and $n$
respectively, and given in that order. For example, the following is a 3x2
matrix:

```text
1   1
5  -42
0  2.5
```

Note that the numbers inside a matrix are rather flexible. Depending on the
circumstances, we might prefer them to be naturals, while in others we might
want reals, or even functions. In order to avoid the complexities here, we will
simply parameterize the our module over the type of numbers, and postulate any
properties of those numbers as the need occurs. Let's call this number type
parameter `ğ”¸`:

```agda
module matrix-induction {ğ”¸ : Set} where
```


### The Row-Major Representation

Returning to the problem of modeling matrices in Agda, note that we don't have
any good, inductive primitives for two-dimensional data, I think most
programmers would thus come up with the next best thing: the "vector of vectors"
model---indeed, it's what I first thought of.

```agda
  open import Data.Product
    as Î£
    using (_Ã—_; _,_)
  open import Data.Nat
    using (â„•; zero; suc)
  open import Data.Vec
    using (Vec; []; _âˆ·_)

  Matrix : â„• â†’ â„• â†’ Set
  Matrix m n = Vec (Vec ğ”¸ n) m

  private variable
    m n p : â„•
```

This representation is known as the "row-major order" of matrices, that is, the
rows have contiguous data, while the columns do not. There are immediate
repercussions here. For example, let's implement the function `top/rest` which
separates the first row from the rest of the matrix:

```agda
  top/rest
      : Matrix (suc m) n
      â†’ Vec ğ”¸ n Ã— Matrix m n
  top/rest (x âˆ· xs) = x , xs
```

Compare `top/rest` to the analogous function that pulls the leftmost column off
of a matrix:

```agda
  left/rest
      : Matrix m (suc n)
      â†’ Vec ğ”¸ m Ã— Matrix m n
  left/rest [] = [] , []
  left/rest ((x âˆ· v) âˆ· m)
    = Î£.map (x âˆ·_) (v âˆ·_) (left/rest m)
```

The dramatic difference in complexity between these two analogous functions is
telling. Clearly, row-major order significantly privileges working with rows
over working with columns.

Nevertheless, we can continue by implementing a few special matrices of note.
First is the zero-matrix, which is the matrix that is full only of zeroes. Note
that we will also need to postulate the existence of `0# : ğ”¸`.

```agda
  postulate 0# : ğ”¸

  open Data.Vec
    using (replicate)

  0â‚˜ : Matrix m n
  0â‚˜ = replicate (replicate 0#)
```

Two matrices of the same dimensions support a kind of addition, given by adding
the respective cells in each of the two columns. That is:

$$
\begin{bmatrix}
a & b & c\\
d & e & f
\end{bmatrix}
+
\begin{bmatrix}
x & y & z\\
t & u & v
\end{bmatrix}
=
\begin{bmatrix}
a + x & b + y & c + z\\
d + t & e + u & f + v
\end{bmatrix}
$$

We can implement this operation over matrices by positing the existence of an
addition over `ğ”¸`, as well as some common-sense identity laws:

```agda
  open import Relation.Binary.PropositionalEquality

  postulate
    _+_ : ğ”¸ â†’ ğ”¸ â†’ ğ”¸
    +-identityË¡ : âˆ€ x â†’ 0# + x â‰¡ x
    +-identityÊ³ : âˆ€ x â†’ x + 0# â‰¡ x

  open Data.Vec
    using (zipWith)
```

Addition of matrices doesn't present us any problems, as pointwise operations
don't need to distinguish between rows and columns. Thus, we can zip the rows
together, zip the corresponding cells together, and add each pair:

```agda
  _+â‚˜_ : Matrix m n â†’ Matrix m n â†’ Matrix m n
  x +â‚˜ y = zipWith (zipWith _+_) x y
```

Let's now prove the trivial fact that `0â‚˜` is a left identity for `+â‚˜`:

```agda
  +â‚˜-identityË¡ : (x : Matrix m n) â†’ 0â‚˜ +â‚˜ x â‰¡ x
```

We can begin, as always, with induction on our argument. The first case, in
which `m â‰¡ 0`, is easy:

```agda
  +â‚˜-identityË¡ [] = refl
```

The case that `n â‰¡ 0` is also easy, although slightly more work, as our
row-major order would suggest:

```agda
  +â‚˜-identityË¡ ([] âˆ· rs)
    rewrite +â‚˜-identityË¡ rs
      = refl
```

We're now left with the induction case. After some obvious rewriting to
eliminate the `0# +_` and the row-recursive case, we're left here:

```agda
  +â‚˜-identityË¡ ((c âˆ· cs) âˆ· rs)
    rewrite +-identityË¡ c
    rewrite +â‚˜-identityË¡ rs
```

with the goal

```goal
  (c âˆ· zipWith _+_ (replicate 0#) cs) âˆ· rs
â‰¡
  (c âˆ· cs) âˆ· rs
```

and it's unclear how to move forwards. It would be nice if our induction just
worked, but, unfortunately, it doesn't. Crossing our fingers that this is not a
serious problem, we can write a little lemma to solve the goal for us:

```agda
      = cong (Î» Ï† â†’ (c âˆ· Ï†) âˆ· rs) (lemma cs)

    where
      lemma
          : âˆ€ {m} (cs : Vec ğ”¸ m)
          â†’ zipWith _+_ (replicate 0#) cs â‰¡ cs
      lemma [] = refl
      lemma (c âˆ· cs)
        rewrite +-identityË¡ c
        rewrite lemma cs
          = refl
```

It's not the tidiest proof in the world, but it certainly gets the job done.
However, we should be wary here; this is our second function in which dealing
with the columns was clunkier than the same operation over the rows.

Addition, however, is not the primary task for which programmers and
mathematicians use matrices. No, the more interesting operation is *matrix
multiplication.* Matrix multiplication, unlike your everyday multiplication, has
a stronger type, and requires our two matrices to have an equal dimension
between them. That is, the matrix on the left must have the same width as the
height of the matrix on the right. That is, given `a : Matrix m n` and `b :
Matrix n p`, we can write the operation `a *â‚˜ b` in symbols as:

$$
\begin{bmatrix}
a_{1,1} & a_{1,2} & \cdots & a_{1,n}\\
a_{2,1} & a_{2,2} & \cdots & a_{2,n}\\
\vdots & \vdots & \ddots & \vdots \\
a_{m,1} & a_{m,2} & \cdots & a_{m,n}
\end{bmatrix}
\times
\begin{bmatrix}
b_{1,1} & b_{1,2} & \cdots & b_{1,p}\\
b_{2,1} & b_{2,2} & \cdots & b_{2,p}\\
\vdots & \vdots & \ddots & \vdots \\
b_{n,1} & b_{n,2} & \cdots & b_{n,p}
\end{bmatrix}
$$

with the result being `c : Matrix m p`, where each cell is given by the formula:

$$
c_{i,j} = \sum_{k = 1}^{n} a_{i,k} \times b_{k, j}
$$

Said another way, the product matrix resulting from a multiplication pairs the
rows of the first matrix with the columns of the second, adding each cell up
pointwise.

If this is your first time seeing matrix multiplication (or even if it isn't,)
it might be unclear what the *intuition* behind matrix multiplication is. Why
does it exist, what does it do, and why should we care about it? We will return
to this question in a moment, but for the time being, resign ourselves to
implementing it in our row-major matrix representation.

We will implement matrix multiplication in two steps; first, by computing the
*outer-product*, which is the analogous operation on vectors (matrices with one
dimension set to 1.) The outer product of two vectors is a matrix using the
length of the first as its height, and the length of the second as its width. In
symbols, the result of:

$$
\begin{bmatrix}
a_{1} \\
a_{2} \\
\vdots \
a_{m}
\end{bmatrix}
\otimes
\begin{bmatrix}
b_{1} \\
b_{2} \\
\vdots \
b_{n}
\end{bmatrix}
$$

is a matrix:

$$
\begin{bmatrix}
a_{1}\times b_{1} & a_{1}\times b_{2} & \cdots & a_{1}\times b_{n}\\
a_{2}\times b_{1} & a_{2}\times b_{2} & \cdots & a_{2}\times b_{n}\\
\vdots & \vdots & \ddots & \vdots \\
a_{m}\times b_{1} & a_{m}\times b_{2} & \cdots & a_{m}\times b_{n}
\end{bmatrix}
$$

It's not too tricky to implement such a thing in Agda; the secret is to write
down the type and use the type-checker to help us ensure that we haven't lost a
case anywhere.

```agda
  open Data.Vec
    using (map)

  postulate
    _*_ : ğ”¸ â†’ ğ”¸ â†’ ğ”¸

  _âŠ—_ : Vec ğ”¸ m â†’ Vec ğ”¸ n â†’ Matrix m n
  []       âŠ— ys = []
  (x âˆ· xs) âŠ— ys = map (x *_) ys âˆ· xs âŠ— ys
```

Now that we have the outer product, we can implement matrix multiplication by
taking the outer product of each row/column pair and doing a matrix addition
with the multiplication of the rest of the matrix. Start with the type:

```agda
  _*â‚˜_ : Matrix m n â†’ Matrix n p â†’ Matrix m p
```

Recall that in the definition of matrix multiplication, the *columns* of the
first matrix get paired with the *rows* of the latter. Since our matrices are in
row-major order, our induction naturally will proceed on the second argument,
since that's where the rows are. If we're out of rows, the result is
conceptually zero, but that doesn't typecheck, so instead we use `0â‚˜` which is
the matrix analogue:

```agda
  x *â‚˜ [] = 0â‚˜
```

Otherwise, we must pair a column from `x` with the row we just pulled off. We
can use `left/rest` to get the column, and then proceed with our outer product
added to the resultant multiplication:

```agda
  x *â‚˜ (r âˆ· rs) =
    let c , cs = left/rest x
      in (c âŠ— r) +â‚˜ (cs *â‚˜ rs)
```

As it happens, this definition of `_*â‚˜_` *is* indeed correct, but it's rather
hard to convince ourselves of that, isn't it? Recall the definition we gave
earlier, where the $c_{i,j}$ element in the resultant matrix was given by the
formula:

$$
c_{i,j} = \sum_{k = 1}^{n} a_{i,k} \times b_{k, j}
$$

Our implementation instead gives us a recursive definition:

$$
a \times_m b = (a_{-, 1} \otimes b_{1, -}) +_m ((a_{-, 2\dots}) \times_m (b_{2\dots, -}))
$$

which uses nonstandard notation to suggest pulling a column off a matrix via
$a_{-, 1}$ and the rest of the matrix as $a_{-, 2\dots}$. We can convince
ourselves of the correctness here by noticing that the induction is actually on
`p`, which means the rows and the columns on which we're doing the outer product
remain of length `m` and `n` respectively. Thus, each outer product still
results in a matrix of size $m \times n$, of which we add up exactly `p` in
number. Thus, our definition here performs `p` matrix additions, while the
mathematical definition performs `p` scalar additions in each cell.

These two definitions are thus equivalent, but there is significantly more
algebraic manipulation necessary to use `_*â‚˜_` as written. Notice that if we
wanted to prove anything about it, we would first need to inline the definitions
of `left/rest`, `_âŠ—_`, and `_+â‚˜_`, each of which is annoyingly recursive and
none of which will Agda automatically compute for us. It's thus rather more work
than we'd like to do! In choosing the row-major order as our representation,
we've obscured the mathematics we're trying to prove. Not only do we need to
still do the original mathematics, we also need to juggle the weight of our
representation.


### Function Representation

Rather than go forward with the row-major representation, we will try again with
a different representation and see how all the same things roll-out. We note
that where things really went wrong was that rows and columns were citizens of
differing standing. It was easy to work with rows, but difficult to work with
columns. Of course, we could always try a column-major ordering instead, but
that would merely move the challenges.

Instead, we find ourselves looking for a representation which doesn't make any
distinctions between the two dimensions. Any sort of inductive definition is
sure to build up matrices from smaller matrices, which is likely to give rise to
the same issues. Let's thus turn our attention to a function representation:

```agda
module matrix-functions {ğ”¸ : Set} where
  open import Data.Nat
    using (â„•; zero; suc)
  open import Data.Fin
    using (Fin; zero; suc)

  Matrix : â„• â†’ â„• â†’ Set
  Matrix m n = (i : Fin m) â†’ (j : Fin n) â†’ ğ”¸
```

A matrix is thus parameterized by its dimensions, and is represented by a
function which takes those indices and gives you back an element of `ğ”¸`. Giving
names to the `Fin` arguments here isn't strictly necessary, but it helps Agda
give meaningful names to indices as we work with matrices.

We can implement the zero matrix trivially, by simply ignoring the indices:

```agda
  private variable
    m n p : â„•

  postulate 0# : ğ”¸

  0â‚˜ : Matrix m n
  0â‚˜ _ _ = 0#
```

Furthermore, we can now implement the identity matrix straightforwardly. In
symbols, the identity function is a square ($n \times n$) matrix whose cells are
given by:

$$
c_{i,j} =
\begin{cases}
  1 & i = j \\
  0 & \text{otherwise}
\end{cases}
$$

In Agda:

```agda
  open import Data.Bool
    using (Bool; true; false; if_then_else_)

  _==_ : Fin n â†’ Fin n â†’ Bool
  zero == zero = true
  zero == suc y = false
  suc x == zero = false
  suc x == suc y = x == y

  postulate 1# : ğ”¸

  1â‚˜ : Matrix m m
  1â‚˜ i j = if i == j then 1# else 0#
```

We can implement the summation operator by way of `sum`, which takes a function
out of `Fin n` and adds up every term:

```agda
  postulate
    _+_ : ğ”¸ â†’ ğ”¸ â†’ ğ”¸

  open import Function
    using (id; _âˆ˜_)

  sum : (Fin n â†’ ğ”¸) â†’ ğ”¸
  sum {zero} v = 0#
  sum {suc n} v = v zero + sum {n} (v âˆ˜ suc)
```

With all of these pieces under our belt, the definition of matrix multiplication
is now extremely simple, and mirrors its mathematical counterpart exactly:

```agda
  postulate
    _*_ : ğ”¸ â†’ ğ”¸ â†’ ğ”¸

  _*â‚˜_ : Matrix m n â†’ Matrix n p â†’ Matrix m p
  (a *â‚˜ b) i j = sum Î» k â†’ a i k * b k j
```

Implementing matrix addition is also exceptionally easy under our new scheme,
corresponding again exactly with the mathematical definition:

```agda
  _+â‚˜_ : Matrix m n â†’ Matrix m n â†’ Matrix m n
  (a +â‚˜ b) i j = a i j + b i j
```

With a little bit of machinery in order to express equality of matrices:

```agda
  open import Relation.Binary.PropositionalEquality

  infix 0 _â‰¡â‚˜_
  _â‰¡â‚˜_ : (a b : Matrix m n) â†’ Set
  a â‰¡â‚˜ b = âˆ€ i j â†’ a i j â‰¡ b i j
```

We can now prove `+â‚˜-identityË¡` again.

```agda
  postulate
    +-identityË¡ : âˆ€ x â†’ 0# + x â‰¡ x

  +â‚˜-identityË¡ : (a : Matrix m n) â†’ 0â‚˜ +â‚˜ a â‰¡â‚˜ a
  +â‚˜-identityË¡ a i j
    rewrite +-identityË¡ (a i j)
      = refl
```

Compare the simplicity of this proof to the previous one we wrote for the
row-major implementation:

```agda
--  +â‚˜-identityË¡ ([] âˆ· rs)
--    rewrite +â‚˜-identityË¡ rs
--      = refl
--  +â‚˜-identityË¡ ((c âˆ· cs) âˆ· rs)
--    rewrite +-identityË¡ c
--    rewrite +â‚˜-identityË¡ rs
--      = cong (Î» Ï† â†’ (c âˆ· Ï†) âˆ· rs) (lemma cs)
--    where
--      lemma
--          : âˆ€ {m} (cs : Vec ğ”¸ m)
--          â†’ zipWith _+_ (replicate 0#) cs â‰¡ cs
--      lemma [] = refl
--      lemma (c âˆ· cs)
--        rewrite +-identityË¡ c
--        rewrite lemma cs
--          = refl
```

Clearly we are onto something with our new representation.








```agda
open import Data.Nat using (â„•; zero; suc)
private variable
  m n p : â„•
  c â„“ : Agda.Primitive.Level
  A B C : Set â„“

open import Function using (id; _âˆ˜_)
open import Relation.Binary.PropositionalEquality

open import Algebra
  using (Semiring)
```

```agda
module WithSemiringâ‚‚ (R : Semiring c â„“) where
    open Semiring R renaming (Carrier to X) using (0#; 1#; _+_; _*_)

    open import Data.Fin using (Fin; zero; suc)

    Vec : â„• â†’ Set c
    Vec m = Fin m â†’ X

    postulate
      fin-ext : {vâ‚ vâ‚‚ : Vec m} â†’ (âˆ€ i â†’ vâ‚ i â‰¡ vâ‚‚ i) â†’ vâ‚ â‰¡ vâ‚‚

    postulate
      *-zeroË¡ : âˆ€ x â†’ 0# * x â‰¡ 0#
      *-zeroÊ³ : âˆ€ x â†’ x * 0# â‰¡ 0#
      +-identityÊ³ : âˆ€ x â†’ x + 0# â‰¡ x
      +-identityË¡ : âˆ€ x â†’ 0# + x â‰¡ x
      *-identityË¡ : âˆ€ x â†’ 1# * x â‰¡ x
      *-+-distribË¡ : âˆ€ x y z â†’ z * (x + y) â‰¡ z * x + z * y
      *-+-distribÊ³ : âˆ€ x y z â†’ (x + y) * z â‰¡ x * z + y * z
      *-comm : âˆ€ x y â†’ x * y â‰¡ y * x

    Matrix : â„• â†’ â„• â†’ Set c
    Matrix m n = Fin m â†’ Fin n â†’ X

    0â‚˜ : Matrix m n
    0â‚˜ _ _ = 0#

    open import Data.Bool using (Bool; true; false; if_then_else_)

    _==_ : Fin n â†’ Fin n â†’ Bool
    zero == zero = true
    zero == suc y = false
    suc x == zero = false
    suc x == suc y = x == y

    1â‚˜ : Matrix m m
    1â‚˜ i j = if i == j then 1# else 0#

    sum : Vec n â†’ X
    sum {zero} v = 0#
    sum {suc n} v = v zero + sum {n} (v âˆ˜ suc)

    sum/0* : (f : Fin m â†’ X) â†’ sum (Î» j â†’ 0# * f j) â‰¡ 0#
    sum/0* {zero} f = refl
    sum/0* {suc m} f
      rewrite sum/0* {m} (f âˆ˜ suc)
            | *-zeroË¡ (f zero)
            | +-identityÊ³ 0#
            = refl


    _*â‚˜_ : Matrix m n â†’ Matrix n p â†’ Matrix m p
    (mâ‚ *â‚˜ mâ‚‚) i k = sum Î» j â†’ mâ‚ i j * mâ‚‚ j k

    column : Vec m â†’ Matrix m 1
    column v i _ = v i

    âŒŠ_âŒ‹ : Matrix m n â†’ Vec n â†’ Vec m
    âŒŠ m âŒ‹ v i = (m *â‚˜ column v) i zero
```

We will first need a little lemma that states that the sum of anything
pointwise-multiplied by zero is also zero:

```agda
    sum/*0 : (f : Fin m â†’ X) â†’ sum (Î» j â†’ f j * 0#) â‰¡ 0#
    sum/*0 {zero} f = refl
    sum/*0 {suc m} f
      rewrite sum/*0 {m} (f âˆ˜ suc)
            | *-zeroÊ³ (f zero)
            | +-identityË¡ 0#
            = refl
```

And we are now ready to show the first of two facts demonstrating that matrices
are just encodings of functions. The first is that `âŒŠ 1â‚˜ âŒ‹` corresponds to the
`id` function:

```agda
    âŒŠ1â‚˜âŒ‹ : (x : Vec m)
         â†’ (i : Fin m)
         â†’ âŒŠ 1â‚˜ {m} âŒ‹ x i â‰¡ x i
```

The type here would be clearer as `âŒŠ 1â‚˜ {m} âŒ‹ â‰— id`, but adding in the `x` and
`i` points allow us to avoid dealing with function extentionality in our proof.
The proof itself is straightforward: pattern match on `i`, and add rewrites to
eliminate the obvious algebraic identities:

```agda
    âŒŠ1â‚˜âŒ‹ x zero
      rewrite (*-identityË¡ (x zero))
            | sum/0* (x âˆ˜ suc)
            | +-identityÊ³ (x zero)
            = refl
    âŒŠ1â‚˜âŒ‹ x (suc i)
      rewrite (*-zeroË¡ (x zero))
            | âŒŠ1â‚˜âŒ‹ (x âˆ˜ suc) i
            | +-identityË¡ (x (suc i))
            = refl
```


```agda
    *â‚˜âŸ¶âˆ˜
      : (mâ‚ : Matrix m n)
      â†’ (mâ‚‚ : Matrix n p)
      â†’ (v : Vec p)
      â†’ (i : Fin m)
      â†’ âŒŠ mâ‚ *â‚˜ mâ‚‚ âŒ‹ v i â‰¡ (âŒŠ mâ‚ âŒ‹ âˆ˜ âŒŠ mâ‚‚ âŒ‹) v i
```

Giving a proof of `*â‚˜âŸ¶âˆ˜` isn't particularly hard on a conceptual level, although
Agda forces us to jump through several hoops to make everything work out
properly. Now that we are working with the function representation of matrices,
we no longer need to play silly games doing induction on the shape of the
matrix; instead, we can do induction on the indices. By binding the implicits
`m`, `n` and `p`, we can see what subgoals fall out when we try destructing on
each.

Destructing on `m` doesn't help simplify anything, but we notice that when
either `n = zero` or `p = zero`, the whole expression must simplify down to
`0#`. Let's do those two cases first, leaving the `suc`/`suc` case for later:

```agda
    *â‚˜âŸ¶âˆ˜ {m} {n} {zero} mâ‚ mâ‚‚ v i rewrite sum/*0 (mâ‚ i) = refl
    *â‚˜âŸ¶âˆ˜ {m} {zero} {p} mâ‚ mâ‚‚ v i rewrite sum/0* v = refl
```

We start by opening a new `â‰¡-Reasoning block:

```agda
    *â‚˜âŸ¶âˆ˜ {m} {suc n} {suc p} mâ‚ mâ‚‚ v i = begin
        âŒŠ mâ‚ *â‚˜ mâ‚‚ âŒ‹ v i
```

Unfortunately, our usual tool of dropping down a reflexive hole and asking Agdda
to normalize-solve it doesn't work here:

```agda
      â‰¡âŸ¨âŸ©
        (mâ‚ *â‚˜ mâ‚‚) i zero * column v zero zero + sum (Î» x â†’ (mâ‚ *â‚˜ mâ‚‚) i (suc x) * column v (suc x) zero)
```

The issue is that Agda is trying to be *too helpful* here and doing an awful job
of it. In fact, Agda normalizes our expression past the point at which the proof
becomes obvious. The solution is tedious, but we must expand out our definitions
ourselves, first, with `âŒŠ_âŒ‹`:

```agda
      â‰¡âŸ¨âŸ©
        ((mâ‚ *â‚˜ mâ‚‚) *â‚˜ column v) i zero
```

and then the outermost `_*â‚˜_`:

```agda
      â‰¡âŸ¨âŸ©
        sum (Î» j â†’ (mâ‚ *â‚˜ mâ‚‚) i j * (column v) j zero)
```

We can now eliminate `column`:

```agda
      â‰¡âŸ¨âŸ©
        sum (Î» j â†’ (mâ‚ *â‚˜ mâ‚‚) i j * v j)
```

and then the remaining `_*â‚˜_`:

```agda
      â‰¡âŸ¨âŸ©
        sum (Î» j â†’ sum (Î» k â†’ mâ‚ i k * mâ‚‚ k j) * column v j zero)
```

Again, eliminate the `column`:

```agda
      â‰¡âŸ¨âŸ©
        sum (Î» j â†’ sum (Î» k â†’ mâ‚ i k * mâ‚‚ k j) * v j)
```

Playing the same game, except from the bottom up, we arrive at:

```agda
      â‰¡âŸ¨ lemma âŸ©
        sum (Î» k â†’ mâ‚ i k * sum (Î» j â†’ mâ‚‚ k j * v j))
      â‰¡âŸ¨âŸ©  -- eliminate column
        sum (Î» k â†’ mâ‚ i k * sum (Î» j â†’ mâ‚‚ k j * column v j zero))
      â‰¡âŸ¨âŸ©  -- expand _*â‚˜_
        sum (Î» k â†’ mâ‚ i k * (mâ‚‚ *â‚˜ column v) k zero)
      â‰¡âŸ¨âŸ©  -- expand âŒŠ_âŒ‹
        sum (Î» k â†’ mâ‚ i k * âŒŠ mâ‚‚ âŒ‹ v k)
      â‰¡âŸ¨âŸ©  -- eliminate column
        sum (Î» k â†’ mâ‚ i k * column (âŒŠ mâ‚‚ âŒ‹ v) k zero)
      â‰¡âŸ¨âŸ©  -- expand  _*â‚˜_
        (mâ‚ *â‚˜ column (âŒŠ mâ‚‚ âŒ‹ v)) i zero
      â‰¡âŸ¨âŸ©  -- expand âŒŠ_âŒ‹
        âŒŠ mâ‚ âŒ‹ (âŒŠ mâ‚‚ âŒ‹ v) i
      â‰¡âŸ¨âŸ©  -- expand _âˆ˜_
        (âŒŠ mâ‚ âŒ‹ âˆ˜ âŒŠ mâ‚‚ âŒ‹) v i
        âˆ
      where
        open â‰¡-Reasoning
```

Most of the work in this proof this proof is already done; it comes from
performing *just enough* evaluation of terms to see that `lemma` is the
interesting piece of the proof. Adding `lemma` to our `where` block:

```agda
        postulate
          lemma
            : sum (Î» j â†’ sum (Î» k â†’ mâ‚ i k * mâ‚‚ k j) * v j)
            â‰¡ sum (Î» k â†’ mâ‚ i k * sum (Î» j â†’ mâ‚‚ k j * v j))
```

we can inspect its type. From here, it's easy to spot that is a trivial fact of
algebra. We must prove the fact that:

$$
\sum_{j}{\left(\sum_{k} {m_{1ik} \times m_{2kj}\right) \times v_j} =
\sum_{k}{m_{1ik} \times \sum_{j} {m_{2kj} \times v_j}
$$

The proof (in Agda) is uninteresting and tedious, thus we will omit it from
presentation here, satisfying ourselves with a postulate. The result, however,
is straightforward, relying only on the associativity and distributivity of
multiplication, and the commutativity of addition:

$$
\begin{align}
\sum_{j}{\left(\sum_{k} {m_{1ik} \times m_{2kj}\right)} \times v_j}
  &= \sum_{j}{\sum_{k} {m_{1ik} \times m_{2kj} \times v_j}} \\
  &= \sum_{k}{\sum_{j} {m_{1ik} \times m_{2kj} \times v_j}} \\
  &= \sum_{k}{m_{1ik} \times \sum_{k} {m_{1ik} \times m_{2kj} \times v_j}}
\end{align}
$$

Here are the gory details if you aren't happy postulating `lemma`:

```agda
            -- â‰¡âŸ¨ cong sum (fin-ext Î» j â†’ sum-scalar (Î» k â†’ mâ‚ i k * mâ‚‚ k j) (v j))  âŸ©
        -- sum (Î» j â†’ sum (Î» k â†’ mâ‚ i k * mâ‚‚ k j * v j))
            -- â‰¡âŸ¨ sum-sum (Î» j k â†’ mâ‚ i k * mâ‚‚ k j * v j) âŸ©
        -- sum (Î» k â†’ sum (Î» j â†’ mâ‚ i k * mâ‚‚ k j * v j))    â‰¡âŸ¨ obvious âŸ©
        -- sum (Î» k â†’ sum (Î» j â†’ mâ‚ i k * (mâ‚‚ k j * v j)))  â‰¡âŸ¨ obvious âŸ©

    sum-scalar : (f : Fin m â†’ X) â†’ (y : X) â†’ sum (Î» x â†’ f x) * y â‰¡ sum (Î» x â†’ f x * y)
    sum-scalar {zero} f y = *-zeroË¡ y
    sum-scalar {suc m} f y =
      begin
        (f zero + sum (Î» x â†’ f (suc x))) * y
      â‰¡âŸ¨ *-+-distribÊ³ (f zero) _ y âŸ©
        f zero * y + sum (Î» x â†’ f (suc x)) * y
      â‰¡âŸ¨ cong (f zero * y +_) (sum-scalar (f âˆ˜ suc) y) âŸ©
        f zero * y + sum (Î» x â†’ f (suc x) * y)
      âˆ
      where open â‰¡-Reasoning

    postulate
      obvious : {x y : X} â†’ x â‰¡ y

    +-sum : (fâ‚ fâ‚‚ : Fin m â†’ X) â†’ sum fâ‚ + sum fâ‚‚ â‰¡ sum (Î» x â†’ fâ‚ x + fâ‚‚ x)
    +-sum {zero} fâ‚ fâ‚‚ = +-identityÊ³ 0#
    +-sum {suc m} fâ‚ fâ‚‚ =
      begin
        fâ‚ zero + sum (Î» x â†’ fâ‚ (suc x)) + (fâ‚‚ zero + sum (Î» x â†’ fâ‚‚ (suc x)))
      â‰¡âŸ¨ obvious âŸ©
        fâ‚ zero + fâ‚‚ zero + (sum (Î» x â†’ fâ‚ (suc x)) + sum (Î» x â†’ fâ‚‚ (suc x)))
      â‰¡âŸ¨ cong (Î» Ï† â†’ fâ‚ zero + fâ‚‚ zero + Ï†) (+-sum (fâ‚ âˆ˜ suc) (fâ‚‚ âˆ˜ suc)) âŸ©
        fâ‚ zero + fâ‚‚ zero + sum (Î» x â†’ fâ‚ (suc x) + fâ‚‚ (suc x))
      âˆ
      where
        open â‰¡-Reasoning


    sum-sum : (f : Fin m â†’ Fin n â†’ X) â†’ sum (Î» j â†’ sum (Î» k â†’ f j k)) â‰¡ sum (Î» k â†’ sum (Î» j â†’ f j k))
    sum-sum {zero} {zero} f = refl
    sum-sum {zero} {suc n} f = obvious
    sum-sum {suc m} {zero} f = obvious
    sum-sum {suc m} {suc n} f =
      begin
        sum {suc m} (Î» j â†’ sum {suc n} (Î» k â†’ f j k))
      â‰¡âŸ¨âŸ©
        sum {suc n} (Î» k â†’ f zero k) + sum {m} (Î» j â†’ sum {suc n} (Î» k â†’ f (suc j) k))
      â‰¡âŸ¨ cong (Î» Ï† â†’ sum {suc n} (Î» k â†’ f zero k) + Ï†) (sum-sum (Î» j k â†’ f (suc j) k)) âŸ©
        sum {suc n} (Î» k â†’ f zero k) + sum {suc n} (Î» k â†’ sum {m} (Î» j â†’ f (suc j) k))
      â‰¡âŸ¨ +-sum (Î» k â†’ f zero k) (Î» k â†’ sum {m} (Î» j â†’ f (suc j) k)) âŸ©
        sum {suc n} (Î» k â†’ f zero k + sum {m} (Î» j â†’ f (suc j) k))
      â‰¡âŸ¨âŸ©
        sum {suc n} (Î» k â†’ sum {suc m} (Î» j â†’ f j k))
      âˆ
      where open â‰¡-Reasoning
```

So, what kind of functions are representable as matrices? As it happens, they
are precisely the *linear maps* --- that is, the two properties must hold:

```agda
    map : (X â†’ X) â†’ Vec m â†’ Vec m
    map f v i = f (v i)

    zip : (X â†’ X â†’ X) â†’ Vec m â†’ Vec m â†’ Vec m
    zip f vâ‚ vâ‚‚ i = f (vâ‚ i) (vâ‚‚ i)

    record LinearFunction (f : Vec m â†’ Vec n) : Set c where
      field
        additive : âˆ€ vâ‚ vâ‚‚ â†’ f (zip _+_ vâ‚ vâ‚‚) â‰— zip _+_ (f vâ‚) (f vâ‚‚)
        homogeneity : âˆ€ v x â†’ f (map (x *_) v) â‰— map (x *_) (f v)
    open LinearFunction

    âŒŠâŒ‹-linear : (M : Matrix m n) â†’ LinearFunction âŒŠ M âŒ‹
    additive (âŒŠâŒ‹-linear M) vâ‚ vâ‚‚ i =
      begin
        âŒŠ M âŒ‹ (zip _+_ vâ‚ vâ‚‚) i
      â‰¡âŸ¨âŸ©
        sum (Î» j â†’ M i j * (vâ‚ j + vâ‚‚ j))
      â‰¡âŸ¨ cong sum (fin-ext Î» j â†’ *-+-distribË¡ _ _ (M i j)) âŸ©
        sum (Î» j â†’ M i j * vâ‚ j + M i j * vâ‚‚ j)
      â‰¡âŸ¨ sym (+-sum (Î» j â†’ M i j * vâ‚ j) (Î» j â†’ M i j * vâ‚‚ j)) âŸ©
        sum (Î» j â†’ M i j * vâ‚ j) + sum (Î» j â†’ M i j * vâ‚‚ j)
      â‰¡âŸ¨âŸ©
        âŒŠ M âŒ‹ vâ‚ i + âŒŠ M âŒ‹ vâ‚‚ i
      âˆ
      where open â‰¡-Reasoning
    homogeneity (âŒŠâŒ‹-linear M) v x i =
      begin
        âŒŠ M âŒ‹ (map (x *_) v) i
      â‰¡âŸ¨âŸ©
        sum (Î» j â†’ M i j * (x * v j))
      â‰¡âŸ¨ obvious âŸ©
        sum (Î» j â†’ M i j * (v j * x))
      â‰¡âŸ¨ obvious âŸ©
        sum (Î» j â†’ (M i j * v j) * x)
      â‰¡âŸ¨ obvious âŸ©
        sum (Î» j â†’ (M i j * v j) * x)
      â‰¡âŸ¨ sym (sum-scalar (Î» j â†’ (M i j * v j)) x) âŸ©
        sum (Î» j â†’ M i j * v j) * x
      â‰¡âŸ¨ *-comm _ x âŸ©
        x * sum (Î» j â†’ M i j * v j)
      â‰¡âŸ¨âŸ©
        map (x *_) (âŒŠ M âŒ‹ v) i
      âˆ
      where open â‰¡-Reasoning
```

```agda

open import Data.Bool using (true; false)
open import Relation.Nullary using (Dec; yes; no; _because_; ofÊ¸)

module dictionaries {K : Set} (_â‰Ÿ_ : (x y : K) â†’ Dec (x â‰¡ y)) where
  open import Data.Maybe using (Maybe; just; nothing)
  open import Data.Product using (_Ã—_; _,_; âˆƒ; Î£; projâ‚; projâ‚‚)

  open import Data.List using (List; []; _âˆ·_; map)
  open import Data.List.Relation.Unary.All using (All; []; _âˆ·_)
  open import Data.List.Relation.Unary.AllPairs using (AllPairs; []; _âˆ·_)
  open import Data.List.Relation.Unary.Unique.Propositional using (Unique; []; _âˆ·_)

  private variable
    V : Set

  UniqueAssocList : (K V : Set) â†’ List (K Ã— V) â†’ Set
  UniqueAssocList _ _ = AllPairs Î» { (kâ‚ , _) (kâ‚‚ , _) â†’ kâ‚ â‰¢ kâ‚‚ }

  Dict : Set â†’ Set â†’ Set
  Dict K V = âˆƒ (UniqueAssocList K V)

  lookup : List (K Ã— V) â†’ K â†’ Maybe V
  lookup [] i = nothing
  lookup ((k , v) âˆ· l) i with i â‰Ÿ k
  ... | yes refl = just v
  ... | no _ = lookup l i

  âŒŠ_âŒ‹ : Dict K V â†’ (K â†’ Maybe V)
  âŒŠ l , _ âŒ‹ = lookup l

  data Preimage_âˆ‹_ (f : K â†’ Maybe V) : K â†’ Set where
    im : âˆ€ {x} y â†’ f x â‰¡ just y â†’ Preimage f âˆ‹ x

  open import Data.List.Membership.Propositional

  record ComputablePreimage (f : K â†’ Maybe V) (l : List K) : Set where
    field
      is-unique : Unique l
      is-preimage : All (Preimage f âˆ‹_) l
      is-total : âˆ€ k v â†’ f k â‰¡ just v â†’ k âˆˆ l
  open ComputablePreimage

  preimage : Dict K V â†’ List K
  preimage (l , _) = map projâ‚ l

  open import Data.List.Relation.Unary.Unique.Propositional.Properties

  postulate
    â‰Ÿ-refl : âˆ€ k â†’ k â‰Ÿ k â‰¡ (true because ofÊ¸ refl)

  open import Data.Empty using (âŠ¥-elim)


--   âŒŠâŒ‹-preimage : (d : Dict K V) â†’ ComputablePreimage âŒŠ d âŒ‹ (preimage d)
--   is-unique (âŒŠâŒ‹-preimage (l , u)) = mapâº ? ?
--   is-preimage (âŒŠâŒ‹-preimage ([] , _)) = []
--   is-preimage (âŒŠâŒ‹-preimage d@((k , v) âˆ· l , _ âˆ· p)) with âŒŠ d âŒ‹ k in eq
--   ... | just v rewrite eq = im v eq âˆ· is-preimage {! âŒŠâŒ‹-preimage (l , p) !}
--   ... | nothing = âŠ¥-elim {! !}
--   is-total (âŒŠâŒ‹-preimage d) = {! !}

-- Fuck preimages.
```

subsets


